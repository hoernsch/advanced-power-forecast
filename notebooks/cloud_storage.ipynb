{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from google.cloud import bigquery, storage\n",
    "\n",
    "from pathlib import Path\n",
    "from colorama import Fore, Style\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from power.ml_ops.data import get_pv_data, clean_pv_data\n",
    "\n",
    "from power.params import *\n",
    "# from power.ml_ops.data import get_data_with_cache, clean_data, load_data_to_bq\n",
    "# from power.ml_ops.model import initialize_model, compile_model, train_model, evaluate_model\n",
    "# from power.ml_ops.preprocessor import preprocess_features\n",
    "# from power.ml_ops.registry import load_model, save_model, save_results\n",
    "# from power.ml_ops.registry import mlflow_run, mlflow_transition_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data with Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_data_with_cache(\n",
    "        gcp_project:str,\n",
    "        query:str,\n",
    "        cache_path:Path,\n",
    "        data_has_header=True\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve `query` data from BigQuery, or from `cache_path` if the file exists\n",
    "    Store at `cache_path` if retrieved from BigQuery for future use\n",
    "    \"\"\"\n",
    "    if cache_path.is_file():\n",
    "        print(Fore.BLUE + \"\\nLoad data from local CSV...\" + Style.RESET_ALL)\n",
    "        df = pd.read_csv(cache_path, header='infer' if data_has_header else None)\n",
    "    else:\n",
    "        print(Fore.BLUE + \"\\nLoad data from BigQuery server...\" + Style.RESET_ALL)\n",
    "        client = bigquery.Client(project=gcp_project)\n",
    "        query_job = client.query(query)\n",
    "        result = query_job.result()\n",
    "        df = result.to_dataframe()\n",
    "\n",
    "        # Store as CSV if the BQ query returned at least one valid line\n",
    "        if df.shape[0] > 1:\n",
    "            df.to_csv(cache_path, header=data_has_header, index=False)\n",
    "\n",
    "    print(f\"✅ Data loaded, with shape {df.shape}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      " ⭐️ Use case: preprocess\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    SELECT *\\n    FROM le-wagon-data-411310.power.raw_pv\\n    ORDER BY _0\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Fore.MAGENTA + \"\\n ⭐️ Use case: preprocess\" + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {GCP_PROJECT_WAGON}.{BQ_DATASET}.raw_pv\n",
    "    ORDER BY _0\n",
    "\"\"\"\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load data from BigQuery server...\u001b[0m\n",
      "✅ Data loaded, with shape (376944, 8)\n"
     ]
    }
   ],
   "source": [
    "# Retrieve data using `get_data_with_cache`\n",
    "data_query_cache_path = Path(LOCAL_DATA_PATH).joinpath(\"raw\", f\"raw_pv.csv\")\n",
    "data_query = get_data_with_cache(\n",
    "    query=query,\n",
    "    gcp_project=GCP_PROJECT,\n",
    "    cache_path=data_query_cache_path,\n",
    "    data_has_header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_bq(\n",
    "        data: pd.DataFrame,\n",
    "        gcp_project:str,\n",
    "        bq_dataset:str,\n",
    "        table: str,\n",
    "        truncate: bool\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    - Save the DataFrame to BigQuery\n",
    "    - Empty the table beforehand if `truncate` is True, append otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(data, pd.DataFrame)\n",
    "    full_table_name = f\"{gcp_project}.{bq_dataset}.{table}\"\n",
    "    print(Fore.BLUE + f\"\\nSave data to BigQuery @ {full_table_name}...:\" + Style.RESET_ALL)\n",
    "\n",
    "    # Load data onto full_table_name\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Define write mode and schema\n",
    "    write_mode = \"WRITE_TRUNCATE\" if truncate else \"WRITE_APPEND\"\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=write_mode)\n",
    "\n",
    "    print(f\"\\n{'Write' if truncate else 'Append'} {full_table_name} ({data.shape[0]} rows)\")\n",
    "\n",
    "    # Load data\n",
    "    job = client.load_table_from_dataframe(data, full_table_name, job_config=job_config)\n",
    "    result = job.result()  # wait for the job to complete\n",
    "\n",
    "    print(f\"✅ Data saved to bigquery, with shape {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_0-1</th>\n",
       "      <th>_0</th>\n",
       "      <th>local_time</th>\n",
       "      <th>electricity</th>\n",
       "      <th>irradiance_direct</th>\n",
       "      <th>irradiance_diffuse</th>\n",
       "      <th>temperature</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>315532800000</td>\n",
       "      <td>1980-01-01 01:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.296</td>\n",
       "      <td>data/pv_data/1980_pv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>315536400000</td>\n",
       "      <td>1980-01-01 02:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.216</td>\n",
       "      <td>data/pv_data/1980_pv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>315540000000</td>\n",
       "      <td>1980-01-01 03:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.005</td>\n",
       "      <td>data/pv_data/1980_pv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>315543600000</td>\n",
       "      <td>1980-01-01 04:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.063</td>\n",
       "      <td>data/pv_data/1980_pv.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>315547200000</td>\n",
       "      <td>1980-01-01 05:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.227</td>\n",
       "      <td>data/pv_data/1980_pv.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _0-1            _0                 local_time  electricity  \\\n",
       "0  <NA>  315532800000  1980-01-01 01:00:00+01:00          0.0   \n",
       "1  <NA>  315536400000  1980-01-01 02:00:00+01:00          0.0   \n",
       "2  <NA>  315540000000  1980-01-01 03:00:00+01:00          0.0   \n",
       "3  <NA>  315543600000  1980-01-01 04:00:00+01:00          0.0   \n",
       "4  <NA>  315547200000  1980-01-01 05:00:00+01:00          0.0   \n",
       "\n",
       "   irradiance_direct  irradiance_diffuse  temperature  \\\n",
       "0                0.0                 0.0       -1.296   \n",
       "1                0.0                 0.0       -1.216   \n",
       "2                0.0                 0.0       -1.005   \n",
       "3                0.0                 0.0       -1.063   \n",
       "4                0.0                 0.0       -1.227   \n",
       "\n",
       "                     source  \n",
       "0  data/pv_data/1980_pv.csv  \n",
       "1  data/pv_data/1980_pv.csv  \n",
       "2  data/pv_data/1980_pv.csv  \n",
       "3  data/pv_data/1980_pv.csv  \n",
       "4  data/pv_data/1980_pv.csv  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_query.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data cleaned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc_time</th>\n",
       "      <th>local_time</th>\n",
       "      <th>electricity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01 00:00:00+00:00</td>\n",
       "      <td>1980-01-01 01:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-01 01:00:00+00:00</td>\n",
       "      <td>1980-01-01 02:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-01 02:00:00+00:00</td>\n",
       "      <td>1980-01-01 03:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-01 03:00:00+00:00</td>\n",
       "      <td>1980-01-01 04:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-01 04:00:00+00:00</td>\n",
       "      <td>1980-01-01 05:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376939</th>\n",
       "      <td>2022-12-31 19:00:00+00:00</td>\n",
       "      <td>2022-12-31 20:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376940</th>\n",
       "      <td>2022-12-31 20:00:00+00:00</td>\n",
       "      <td>2022-12-31 21:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376941</th>\n",
       "      <td>2022-12-31 21:00:00+00:00</td>\n",
       "      <td>2022-12-31 22:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376942</th>\n",
       "      <td>2022-12-31 22:00:00+00:00</td>\n",
       "      <td>2022-12-31 23:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376943</th>\n",
       "      <td>2022-12-31 23:00:00+00:00</td>\n",
       "      <td>2023-01-01 00:00:00+01:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376944 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        utc_time                 local_time  electricity\n",
       "0      1980-01-01 00:00:00+00:00  1980-01-01 01:00:00+01:00          0.0\n",
       "1      1980-01-01 01:00:00+00:00  1980-01-01 02:00:00+01:00          0.0\n",
       "2      1980-01-01 02:00:00+00:00  1980-01-01 03:00:00+01:00          0.0\n",
       "3      1980-01-01 03:00:00+00:00  1980-01-01 04:00:00+01:00          0.0\n",
       "4      1980-01-01 04:00:00+00:00  1980-01-01 05:00:00+01:00          0.0\n",
       "...                          ...                        ...          ...\n",
       "376939 2022-12-31 19:00:00+00:00  2022-12-31 20:00:00+01:00          0.0\n",
       "376940 2022-12-31 20:00:00+00:00  2022-12-31 21:00:00+01:00          0.0\n",
       "376941 2022-12-31 21:00:00+00:00  2022-12-31 22:00:00+01:00          0.0\n",
       "376942 2022-12-31 22:00:00+00:00  2022-12-31 23:00:00+01:00          0.0\n",
       "376943 2022-12-31 23:00:00+00:00  2023-01-01 00:00:00+01:00          0.0\n",
       "\n",
       "[376944 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = clean_pv_data(data_query)\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Save data to BigQuery @ le-wagon-data-411310.power.processed_pv...:\u001b[0m\n",
      "\n",
      "Write le-wagon-data-411310.power.processed_pv (376944 rows)\n",
      "✅ Data saved to bigquery, with shape (376944, 3)\n"
     ]
    }
   ],
   "source": [
    "load_data_to_bq(\n",
    "        clean_data,\n",
    "        gcp_project=GCP_PROJECT,\n",
    "        bq_dataset=BQ_DATASET,\n",
    "        table=f'processed_pv',\n",
    "        truncate=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model in GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: keras.Model = None) -> None:\n",
    "    \"\"\"\n",
    "    Persist trained model locally on the hard drive at f\"{LOCAL_REGISTRY_PATH}/models/{timestamp}.h5\"\n",
    "    - if MODEL_TARGET='gcs', also persist it in your bucket on GCS at \"models/{timestamp}.h5\" --> unit 02 only\n",
    "    - if MODEL_TARGET='mlflow', also persist it on MLflow instead of GCS (for unit 0703 only) --> unit 03 only\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # Save model locally\n",
    "    model_path = os.path.join(LOCAL_REGISTRY_PATH, \"models\", f\"{timestamp}.h5\")\n",
    "    model.save(model_path)\n",
    "\n",
    "    print(\"✅ Model saved locally\")\n",
    "\n",
    "\n",
    "\n",
    "    model_filename = model_path.split(\"/\")[-1] # e.g. \"20230208-161047.h5\" for instance\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(BUCKET_NAME)\n",
    "    blob = bucket.blob(f\"models/{model_filename}\")\n",
    "    blob.upload_from_filename(model_path)\n",
    "\n",
    "    print(\"✅ Model saved to GCS\")\n",
    "\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
