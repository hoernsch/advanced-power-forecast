{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 16:06:03.673079: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-08 16:06:03.832001: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-08 16:06:03.834895: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-08 16:06:06.719132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from colorama import Fore, Style\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from power.params import *\n",
    "from power.ml_ops.data import get_data_with_cache, load_data_to_bq\n",
    "# from power.ml_ops.model import initialize_model, compile_model, train_model, evaluate_model\n",
    "from power.ml_ops.registry import load_model, save_model, save_results\n",
    "# from power.ml_ops.registry import mlflow_run, mlflow_transition_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prediction_date = \"2019-12-10 00:00:00\"\n",
    "# make api call\n",
    "base_url = \"http://127.0.0.1:8000\"\n",
    "endpoint_model = \"/predict/previous_value\"\n",
    "endpoint_data = \"/extract_data\"\n",
    "url_model = f\"{base_url}{endpoint_model}\"\n",
    "url_data = f\"{base_url}{endpoint_data}\"\n",
    "\n",
    "params ={\n",
    "    'input_date':input_prediction_date\n",
    "    }\n",
    "\n",
    "response_model = requests.get(url_model, params=params).json()\n",
    "model_df = pd.DataFrame(response_model)\n",
    "\n",
    "response_data = requests.get(url_data, params=params).json()\n",
    "data_df = pd.DataFrame(response_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2019-12-10 00:00:00': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.01,\n",
       "  0.068,\n",
       "  0.173,\n",
       "  0.402,\n",
       "  0.419,\n",
       "  0.349,\n",
       "  0.165,\n",
       "  0.012,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "⭐️ Use case: train\u001b[0m\n",
      "\u001b[34m\n",
      "Loading preprocessed validation data...\u001b[0m\n",
      "\u001b[34m\n",
      "Load data from BigQuery server...\u001b[0m\n",
      "✅ Data loaded, with shape (376944, 3)\n"
     ]
    }
   ],
   "source": [
    "print(Fore.MAGENTA + \"\\n⭐️ Use case: train\" + Style.RESET_ALL)\n",
    "print(Fore.BLUE + \"\\nLoading preprocessed validation data...\" + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "# Load processed data using `get_data_with_cache` in chronological order\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {GCP_PROJECT}.{BQ_DATASET}.processed_pv\n",
    "    ORDER BY utc_time\n",
    "\"\"\"\n",
    "\n",
    "data_processed_cache_path = Path(LOCAL_DATA_PATH).joinpath(\"processed\", f\"processed_pv.csv\")\n",
    "data_processed = get_data_with_cache(\n",
    "    gcp_project=GCP_PROJECT,\n",
    "    query=query,\n",
    "    cache_path=data_processed_cache_path,\n",
    "    data_has_header=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
