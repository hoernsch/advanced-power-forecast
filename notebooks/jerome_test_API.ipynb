{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from power.ml_ops.data import get_pv_data, clean_pv_data, get_data_with_cache, get_stats_table\n",
    "from power.ml_ops.model import model_yesterday\n",
    "from power.ml_ops.registry import load_model\n",
    "from power.interface.main import pred\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from power.params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(\n",
    "  today: str,\n",
    "  preprocessed_df: pd.DataFrame,\n",
    "  stats_df: pd.DataFrame,\n",
    "  pred_df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Create a df that contains all information necessary for the plot in streamlit.\n",
    "  Input:\n",
    "    -\n",
    "  Output:\n",
    "    -\n",
    "  \"\"\"\n",
    "  # define time period (3 days) for plotting\n",
    "  today_timestamp = pd.Timestamp(today, tz='UTC')\n",
    "  window_df= pd.date_range(\n",
    "            start=today_timestamp - pd.Timedelta(days=2),\n",
    "            end=  today_timestamp + pd.Timedelta(days=1),\n",
    "            freq=pd.Timedelta(hours=1)).to_frame(index=False, name='utc_time')\n",
    "\n",
    "  # create df with the preprocessed data in the time window\n",
    "\n",
    "  plot_df = pd.merge(window_df, preprocessed_df, on='utc_time', how='inner')\n",
    "\n",
    "  # add statistics in the time window\n",
    "  plot_df['hour_of_year'] = plot_df.utc_time.\\\n",
    "                           apply(lambda x: x.strftime(\"%m%d%H\"))\n",
    "  stats_df.columns = stats_df.columns.droplevel(level=0)\n",
    "  plot_df = pd.merge(plot_df, stats_df, on='hour_of_year', how='inner')\n",
    "\n",
    "  # add prediction for day-ahead in time window\n",
    "  input_pred = f\"{today} 12:00:00\" # '2013-05-08 12:00:00'\n",
    "  pred_df = pred(input_pred)\n",
    "  plot_df = pd.merge(plot_df, pred_df, on='utc_time', how='left')\n",
    "\n",
    "  return plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed_cache_path = Path(LOCAL_DATA_PATH).joinpath(\"processed\", f\"processed_pv.csv\")\n",
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {GCP_PROJECT}.{BQ_DATASET}.processed_pv\n",
    "    ORDER BY utc_time\n",
    "\"\"\"\n",
    "\n",
    "data_processed = get_data_with_cache(\n",
    "    gcp_project=GCP_PROJECT,\n",
    "    query=query,\n",
    "    cache_path=data_processed_cache_path,\n",
    "    data_has_header=True\n",
    ")\n",
    "\n",
    "def visualisation(input_date: str, power_source='pv'):\n",
    "  today = input_date\n",
    "  preprocessed_df = data_processed\n",
    "  stats_df = get_stats_table(data_processed, capacity=False)\n",
    "  # dummy (use predict function instead)\n",
    "  pred_df = data_processed[['utc_time','electricity']]\n",
    "  pred_df = pred_df.rename(columns={'electricity':'pred'})\n",
    "  #\n",
    "  plot_df = postprocess(today, preprocessed_df, stats_df, pred_df)\n",
    "  # as dict for data transfer from backend to frontend\n",
    "  plot_dict = plot_df.to_dict()\n",
    "\n",
    "  return plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prediction_date = \"2019-12-10 00:00:00\"\n",
    "# make api call\n",
    "base_url = \"http://127.0.0.1:8000\"\n",
    "\n",
    "# model\n",
    "params_model ={\n",
    "    'input_date':input_prediction_date,\n",
    "    'n_days': 2,\n",
    "    'power_source': 'pv'\n",
    "    }\n",
    "\n",
    "endpoint_model = \"/baseline_yesterday\"\n",
    "url_model= f\"{base_url}{endpoint_model}\"\n",
    "response_model = requests.get(url_model, params_model).json()\n",
    "\n",
    "# baseline\n",
    "params_baseline ={\n",
    "    'input_date':input_prediction_date,\n",
    "    'n_days': 2,\n",
    "    'power_source': 'pv'\n",
    "    }\n",
    "\n",
    "endpoint_baseline = \"/baseline_yesterday\"\n",
    "url_baseline= f\"{base_url}{endpoint_baseline}\"\n",
    "response_baseline = requests.get(url_baseline, params_baseline).json()\n",
    "\n",
    "# data\n",
    "params_data ={\n",
    "    'input_date':input_prediction_date,\n",
    "    'n_days': 10,\n",
    "    'power_source': 'pv'\n",
    "    }\n",
    "\n",
    "endpoint_data = \"/extract_data\"\n",
    "url_data = f\"{base_url}{endpoint_data}\"\n",
    "response_data = requests.get(url_data, params_data).json()\n",
    "\n",
    "# Visualisation\n",
    "params_visu ={\n",
    "    'input_date':input_prediction_date,   # today = '2000-05-15' # would come from streamlit user\n",
    "    'power_source': 'pv'\n",
    "    }\n",
    "endpoint_visu = \"/visualisation\"\n",
    "url_visu = f\"{base_url}{endpoint_visu}\"\n",
    "response_visu = requests.get(url_visu, params_visu).json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up 4 DatFrames according to input date and type of model\n",
    "X = pd.DataFrame(response_data.get(input_prediction_date)['days_before'])\n",
    "y = pd.DataFrame(response_data.get(input_prediction_date)['day_after'])\n",
    "y_baseline = pd.DataFrame(response_baseline.get(input_prediction_date))\n",
    "y_predicted = pd.DataFrame(response_model.get('dataframe to predict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date columns to datetime object\n",
    "X.date = pd.to_datetime(X.date,utc=True)\n",
    "y.date = pd.to_datetime(y.date, utc=True)\n",
    "y_baseline.date = pd.to_datetime(y_baseline.date, utc=True) + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X.date, X.power_source, label='current production data')\n",
    "ax.plot(y.date, y.power_source, label='current production data')\n",
    "ax.plot(y_baseline.date, y_baseline.power_source, label='current production data')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 3, sharex=True, sharey=True)\n",
    "ax[0].plot(X.date, X.power_source, label='current production data')\n",
    "ax[1].plot(y.date, y.power_source, label='current production data')\n",
    "ax[2].plot(y_baseline.date, y_baseline.power_source, label='current production data')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "mean_training = X.power_source.mean()\n",
    "mean_predicted = y_baseline.power_source.mean()\n",
    "mean_diff = mean_predicted - mean_training\n",
    "mean_training, mean_predicted,mean_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests API endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_baseline_yesterday(input_date: str):\n",
    "    data = data_pv_clean[data_pv_clean['utc_time'] < input_date][-24:]\n",
    "    values = data.electricity.to_list()\n",
    "    return {input_date: values}\n",
    "\n",
    "predict_baseline_yesterday(input_prediction_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pv_data(input_date: str, n_days=10):\n",
    "    \"\"\"\n",
    "    Returns the power data for the n_days before the input date\n",
    "    Also returns the power data for the following day\n",
    "    \"\"\"\n",
    "    n_rows = 24 * n_days\n",
    "    days_before = data_pv_clean[data_pv_clean['utc_time'] < input_date] \\\n",
    "                                        ['electricity'][-n_rows:].to_list()\n",
    "    day_after = data_pv_clean[data_pv_clean['utc_time'] >= input_date] \\\n",
    "                                        ['electricity'][:24].to_list()\n",
    "\n",
    "\n",
    "    extracted_data = {\n",
    "        'days_before':days_before,\n",
    "        'day_after':day_after\n",
    "        }\n",
    "\n",
    "    return {input_date: extracted_data}\n",
    "\n",
    "# extract_pv_data(input_prediction_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_date: str, n_days=2):\n",
    "    pv_data_clean = data_pv_clean\n",
    "    X_pred = pv_data_clean[pv_data_clean['utc_time'] < input_date][-48:]\n",
    "\n",
    "    return {'dataframe to predict': X_pred.electricity.to_list()}\n",
    "\n",
    "# predict(input_prediction_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
